# **ASL Translator Studio ğŸ‘Œ**

An interactive, AI-powered **American Sign Language (ASL) Translator and Learning Platform** built with **Streamlit**, **YOLO**, and **WebRTC**.
This project allows users to learn and practice ASL letters (Aâ€“Z) in real time using their webcam. It also provides **speech-to-text**, **sentence building**, **practice mode**, and a **gamified learning experience**.

---

## ğŸš€ Features

* ğŸ™ **Speech to Text**: Convert spoken words to text in multiple languages.
* ğŸ– **ASL Detection**: Real-time ASL letter recognition using YOLO and webcam input.
* âœ **Sentence Builder**: Construct words and sentences by signing letters.
* ğŸ§  **Practice Mode**: Train with random letters, track accuracy, and get instant feedback.
* ğŸ® **Game Mode**: Timed ASL challenge with scoring, attempts tracking, and accuracy metrics.
* ğŸ“Š **Streamlit Interface**: User-friendly sidebar navigation with session state management.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py              # Cloud Enviroment Deployment
â”œâ”€â”€ draft.py            # Local Enviroment Deployment
â”œâ”€â”€ requirements.txt    # Python Dependencies
â”œâ”€â”€ asl_detecton.ipynb  # ASL Model Building
â”œâ”€â”€ best-lite.pt        # Pretrained YOLO model for ASL (Included in Repo)
â””â”€â”€ README.md           # Project Documentation
```

---

## ğŸ›  Installation

1. Clone this repository:

   ```bash
   git clone https://github.com/<your-username>/<your-repo>.git
   cd <your-repo>
   ```

2. Create a virtual environment (recommended):

   ```bash
   python -m venv venv
   source venv/bin/activate   # On Mac/Linux
   venv\Scripts\activate      # On Windows
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. Place your trained YOLO model file (`best-lite.pt`) in the project root directory.

---

## â–¶ï¸ Usage

Run the Streamlit app locally:

```bash
streamlit run app.py
```

The app will start at: [http://localhost:8501](http://localhost:8501)

---

## â˜ï¸ Deployment

This project can run both **locally** and on **Streamlit Cloud**.
To deploy on **Streamlit Cloud**:

1. Push this repo to GitHub.
2. Go to [Streamlit Cloud](https://share.streamlit.io/).
3. Connect your repo and deploy `app.py`.

> âš ï¸ Note: Make sure `requirements.txt` includes all required dependencies and `best-lite.pt` is uploaded or hosted separately.

---

## ğŸ“Š Requirements

All dependencies are listed in `requirements.txt`.
Example key dependencies:

* `streamlit`
* `streamlit-webrtc`
* `ultralytics`
* `opencv-python`
* `speechrecognition`
* `av`
* `streamlit-option-menu`

---

## ğŸ“– Lessons & Future Work

* Improve ASL detection accuracy with more robust YOLO training datasets.
* Extend support beyond alphabet letters to full ASL words and sentences.
* Add **Text-to-Speech (TTS)** for signed sentences.
* Explore **multi-user support** for collaborative ASL learning.

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what youâ€™d like to change.

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

ğŸ‘‰ Would you like me to also **create the `requirements.txt`** for you (based exactly on your imports) so itâ€™s clean and works on Streamlit Cloud without errors?
